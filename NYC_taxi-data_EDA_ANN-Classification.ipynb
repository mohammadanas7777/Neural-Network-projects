{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05405c4-25a2-4ed6-ae8e-b90e0d7f098d",
   "metadata": {},
   "source": [
    "# Full ANN code on New York taxi fare class estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6395710-757c-44a7-ab67-6da18e9ea581",
   "metadata": {},
   "source": [
    "This project implements an Artificial Neural Network (ANN) in PyTorch to describe whether the predicted fare amount will be greater than 10 dollar or not, based on trip details in New York City. The model takes both continuous features (e.g., 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count') and categorical features as inputs. 'fare_class' column basically defines whether or not the fare amount is greater than $10.\n",
    "\n",
    "Data preprocessing involved handling categorical variables via embeddings, normalization of continuous features, and splitting into training/validation/test sets. The ANN model was trained using Cross-Entropy loss and optimized with Adam optimizer, with regularization techniques such as dropout and batch normalization to improve generalization.\n",
    "\n",
    "Performance was evaluated by measuring accuracy. The trained model was saved and can be reloaded for inference or further training.\n",
    "\n",
    "This project demonstrates the effectiveness of ANN in solving a real-world classification problem and showcases model deployment readiness for fare prediction applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "105a3098-78bd-4fd2-b68c-77f427f6a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "da0b830a-9cb7-4c13-9457-5530e085ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/NYCTaxiFares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "fe9538b3-729c-4a30-be9b-97be15c3a899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "3768a14b-c2f5-4895-9200-ce5a54a5ae27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_class\n",
       "0    80000\n",
       "1    40000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "00ca7c27-cbc9-4a1e-9d11-b80c350f06ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.040326</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-73.976626</td>\n",
       "      <td>40.751443</td>\n",
       "      <td>-73.974501</td>\n",
       "      <td>40.751695</td>\n",
       "      <td>1.347167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.500134</td>\n",
       "      <td>0.471406</td>\n",
       "      <td>0.031497</td>\n",
       "      <td>0.025821</td>\n",
       "      <td>0.032419</td>\n",
       "      <td>0.030279</td>\n",
       "      <td>0.759263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.465447</td>\n",
       "      <td>40.121653</td>\n",
       "      <td>-74.443323</td>\n",
       "      <td>40.164927</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.992386</td>\n",
       "      <td>40.736594</td>\n",
       "      <td>-73.991478</td>\n",
       "      <td>40.735914</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.982084</td>\n",
       "      <td>40.753661</td>\n",
       "      <td>-73.980411</td>\n",
       "      <td>40.754441</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.968710</td>\n",
       "      <td>40.768020</td>\n",
       "      <td>-73.965500</td>\n",
       "      <td>40.768880</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.311845</td>\n",
       "      <td>40.981292</td>\n",
       "      <td>-73.496140</td>\n",
       "      <td>40.993498</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fare_amount     fare_class  pickup_longitude  pickup_latitude  \\\n",
       "count  120000.000000  120000.000000     120000.000000    120000.000000   \n",
       "mean       10.040326       0.333333        -73.976626        40.751443   \n",
       "std         7.500134       0.471406          0.031497         0.025821   \n",
       "min         2.500000       0.000000        -74.465447        40.121653   \n",
       "25%         5.700000       0.000000        -73.992386        40.736594   \n",
       "50%         7.700000       0.000000        -73.982084        40.753661   \n",
       "75%        11.300000       1.000000        -73.968710        40.768020   \n",
       "max        49.900000       1.000000        -73.311845        40.981292   \n",
       "\n",
       "       dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "count      120000.000000     120000.000000    120000.000000  \n",
       "mean          -73.974501         40.751695         1.347167  \n",
       "std             0.032419          0.030279         0.759263  \n",
       "min           -74.443323         40.164927         1.000000  \n",
       "25%           -73.991478         40.735914         1.000000  \n",
       "50%           -73.980411         40.754441         1.000000  \n",
       "75%           -73.965500         40.768880         1.000000  \n",
       "max           -73.496140         40.993498         5.000000  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "be46a5fc-fb27-4658-8940-0ee0a9ee3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine function\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # Convert degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    # Earth radius in kilometers\n",
    "    r = 6371\n",
    "    return c * r\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['distance_travelled'] = haversine(\n",
    "    df['pickup_longitude'],\n",
    "    df['pickup_latitude'],\n",
    "    df['dropoff_longitude'],\n",
    "    df['dropoff_latitude']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "3df867c8-cd24-4f32-8334-fd9717d9af3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_travelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "   distance_travelled  \n",
       "0            2.126312  \n",
       "1            1.392307  \n",
       "2            3.326763  \n",
       "3            1.864129  \n",
       "4            7.231321  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "6c43c1ac-69d7-4af6-bb8d-b8b4a59a679d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46019      0.010208\n",
       "62056      0.010210\n",
       "9882       0.010250\n",
       "109630     0.010353\n",
       "110814     0.010477\n",
       "            ...    \n",
       "118513    26.781598\n",
       "20377     26.911161\n",
       "108382    26.976530\n",
       "29074     27.475873\n",
       "8614      28.846365\n",
       "Name: distance_travelled, Length: 120000, dtype: float64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['distance_travelled'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c6d8f-ff46-4494-8ae9-bb14d9640192",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "As distance is not that great this means all the trips are within the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a43a3443-b744-49bb-b7e9-741537b9b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "a7c24ab8-e5f1-46b4-bff3-a588ae3217b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype              \n",
      "---  ------              --------------   -----              \n",
      " 0   pickup_datetime     120000 non-null  datetime64[ns, UTC]\n",
      " 1   fare_amount         120000 non-null  float64            \n",
      " 2   fare_class          120000 non-null  int64              \n",
      " 3   pickup_longitude    120000 non-null  float64            \n",
      " 4   pickup_latitude     120000 non-null  float64            \n",
      " 5   dropoff_longitude   120000 non-null  float64            \n",
      " 6   dropoff_latitude    120000 non-null  float64            \n",
      " 7   passenger_count     120000 non-null  int64              \n",
      " 8   distance_travelled  120000 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(6), int64(2)\n",
      "memory usage: 8.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "4e4a9919-746e-4541-beb1-ced1bb0da359",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_time = df['pickup_datetime'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "00b18085-c49e-4658-829a-fccf2a1eb466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_time.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "694074c0-e762-439b-ae6e-b285d308b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['pickup_datetime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0444c6a4-2ae5-455a-83d6-653729e9619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_travelled</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56+00:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53+00:00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26+00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03+00:00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01+00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
       "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
       "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
       "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
       "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "   distance_travelled  month  \n",
       "0            2.126312      4  \n",
       "1            1.392307      4  \n",
       "2            3.326763      4  \n",
       "3            1.864129      4  \n",
       "4            7.231321      4  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "62a4c57a-6ffc-49e7-b10b-afe7a6806ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "4    120000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4ece0-8f0d-4acf-b3b3-a8a7fbf33694",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Here, we can see that all the records are for the month of April. Therefore, UTC-4 is the timezone. If it was winter then UTC-5 should be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "e79568d6-a4bc-4ddd-9dc2-916921e89302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ETD_datetime'] = df['pickup_datetime'] - pd.Timedelta(hours = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "90234bbf-9e3c-421c-833a-2171d52abc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = df['ETD_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "2b133166-75d7-46c8-ae7e-08278f860947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AM/PM'] = df['Hour'].apply(lambda x: 'AM' if x < 12 else 'PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "afd25d16-6733-4789-a246-57025eb8bb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_travelled</th>\n",
       "      <th>month</th>\n",
       "      <th>ETD_datetime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AM/PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56+00:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-19 04:17:56+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53+00:00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-17 11:43:53+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26+00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-17 07:23:26+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03+00:00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-11 17:25:03+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01+00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-16 22:19:01+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
       "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
       "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
       "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
       "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "   distance_travelled  month              ETD_datetime  Hour AM/PM  \n",
       "0            2.126312      4 2010-04-19 04:17:56+00:00     4    AM  \n",
       "1            1.392307      4 2010-04-17 11:43:53+00:00    11    AM  \n",
       "2            3.326763      4 2010-04-17 07:23:26+00:00     7    AM  \n",
       "3            1.864129      4 2010-04-11 17:25:03+00:00    17    PM  \n",
       "4            7.231321      4 2010-04-16 22:19:01+00:00    22    PM  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "21be0819-7335-4d73-b66a-395180f2978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekday'] = df['ETD_datetime'].dt.strftime(\"%a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "201dcea0-b8e1-4b77-9d63-a867c0592438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday\n",
       "Sun    13328\n",
       "Mon    15509\n",
       "Tue    17189\n",
       "Wed    17360\n",
       "Sat    18355\n",
       "Thu    18539\n",
       "Fri    19720\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "133aa13d-71d0-4c27-8f83-3cb75d71d2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'distance_travelled', 'month', 'ETD_datetime',\n",
       "       'Hour', 'AM/PM', 'Weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7900d818-8fdc-4cc7-a21f-ada5d2b9c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Hour','AM/PM','Weekday']\n",
    "continuous_columns = ['pickup_longitude',\n",
    "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "       'passenger_count', 'distance_travelled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "77d346cb-b229-4dd8-85dd-f30179699703",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = ['fare_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "e77054e9-17f4-4072-975c-8aec816732ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype              \n",
      "---  ------              --------------   -----              \n",
      " 0   pickup_datetime     120000 non-null  datetime64[ns, UTC]\n",
      " 1   fare_amount         120000 non-null  float64            \n",
      " 2   fare_class          120000 non-null  int64              \n",
      " 3   pickup_longitude    120000 non-null  float64            \n",
      " 4   pickup_latitude     120000 non-null  float64            \n",
      " 5   dropoff_longitude   120000 non-null  float64            \n",
      " 6   dropoff_latitude    120000 non-null  float64            \n",
      " 7   passenger_count     120000 non-null  int64              \n",
      " 8   distance_travelled  120000 non-null  float64            \n",
      " 9   month               120000 non-null  int32              \n",
      " 10  ETD_datetime        120000 non-null  datetime64[ns, UTC]\n",
      " 11  Hour                120000 non-null  int32              \n",
      " 12  AM/PM               120000 non-null  object             \n",
      " 13  Weekday             120000 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(6), int32(2), int64(2), object(2)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "eb5cfa83-3651-4eb8-b973-240dab08b6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: int32"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "27d7c992-ba87-403b-8593-fd5320914ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_columns:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "db95dd85-fcf0-4458-bc76-3a0334a07c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: category\n",
       "Categories (24, int32): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7f80b0-dc8d-4ff0-94b6-7826a6a2948f",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Reason to convert some non-continuous columns to categorical columns:\n",
    "1. ML models need numerical inputs which can be acheived by one-hot encoding.\n",
    "2. We can also further converts into label encoding.\n",
    "3. Improves efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "04aaf542-19c4-4bc2-bb8e-e84dc14a8502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         2\n",
       "2         2\n",
       "3         3\n",
       "4         0\n",
       "         ..\n",
       "119995    3\n",
       "119996    0\n",
       "119997    3\n",
       "119998    5\n",
       "119999    2\n",
       "Length: 120000, dtype: int8"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "df['Weekday'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d1a26c22-d676-45b4-8fc8-edfdef6ed805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building our feature columns\n",
    "cat_col = torch.tensor(np.stack([df[col].cat.codes for col in cat_columns], axis = 1), dtype = torch.int64)\n",
    "cont_col = torch.tensor(np.stack([df[cont].values for cont in continuous_columns], axis = 1), dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0ff592d0-1319-4a2b-91e5-7ee56d1cc390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-73.9924,  40.7305, -73.9755,  40.7447,   1.0000,   2.1263],\n",
       "        [-73.9901,  40.7406, -73.9742,  40.7441,   1.0000,   1.3923],\n",
       "        [-73.9941,  40.7511, -73.9601,  40.7662,   2.0000,   3.3268],\n",
       "        ...,\n",
       "        [-73.9886,  40.7498, -74.0115,  40.7078,   3.0000,   5.0525],\n",
       "        [-74.0044,  40.7245, -73.9927,  40.7308,   1.0000,   1.2089],\n",
       "        [-73.9554,  40.7719, -73.9676,  40.7630,   3.0000,   1.4274]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "96729feb-26bc-4bf0-aaf4-2f46c216b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count   Dtype\n",
      "---  ------      --------------   -----\n",
      " 0   fare_class  120000 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Building the output column\n",
    "df[y_col].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "303cd144-33aa-476a-a669-4cf02841ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = torch.tensor(df[y_col].values).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "6e8300a2-8c2c-487d-9b76-3634705b8541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "de4ee73c-982a-4530-be67-e9ec27b6ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sizes = [len(df[col].cat.categories) for col in cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "9dd27e9c-2c70-42dd-b245-85c3982f0801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 2, 7]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcadf81c-904c-48e3-bcc1-8244b8a813b8",
   "metadata": {},
   "source": [
    "\"Now, here we can do one-hot encoding for the categorical values, but it will unnecessarily increase the size of the data and memory. Instead, we can use embeddings, which are a better option because they create dense, low-dimensional representations that:\n",
    "* reduce memory and computational cost,\n",
    "* avoid sparsity,\n",
    "* and capture similarity between categories, improving model performance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e361aadb-e307-4c45-8a71-b10939a9f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To decide the size of the embedding for each categorical columns\n",
    "emb_sizes = [(size,min(24,(size+1)//2)) for size in cat_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "360683fd-aa1f-49ec-9c4a-0c60daa18e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbf731-a80e-4023-b136-a515e8884ed9",
   "metadata": {},
   "source": [
    "This means first categorical column will be represented by combination of 12 different float numbers. Similarly second and third column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "fc8e135d-6269-4e9a-a549-03d57cdc7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "# Here ni = no_of_unique_category_values & nf = size_of_embedding\n",
    "# nn.ModuleList will wrap the list comprehension so that pytorch will knows they are a part of the model.\n",
    "\n",
    "selfembeds = nn.ModuleList([nn.Embedding(ni,nf) for ni,nf in emb_sizes])\n",
    "embeddings = []\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddings.append(e(cat_col[:,i]))\n",
    "\n",
    "new_cat_col = torch.cat(embeddings,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "3f468891-e8f7-4b55-927a-544ed04cbdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1465,  0.3005,  0.7932,  ...,  0.5924, -0.6519,  1.3289],\n",
       "        [ 1.4879,  1.0030,  0.4124,  ...,  1.2790, -0.7287, -0.8346],\n",
       "        [ 0.8127, -0.7423,  0.2958,  ...,  1.2790, -0.7287, -0.8346],\n",
       "        ...,\n",
       "        [-0.1620, -0.0213, -1.7451,  ..., -0.2123, -0.2889, -0.3224],\n",
       "        [ 1.1465,  0.3005,  0.7932,  ..., -1.4911,  0.3306, -0.1553],\n",
       "        [-1.1572, -1.1982,  1.4401,  ...,  1.2790, -0.7287, -0.8346]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cat_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d60d7-8dc2-47f6-8802-8c8dc4be5ae2",
   "metadata": {},
   "source": [
    "#### Now, in order to reduce the size and increase the computational efficiency we drop the values which are having a lesser probability to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "73efbdd1-e8da-43cf-936d-f5cb9917e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the values which are having p < 0.4 \n",
    "# Meaning: during training, 40% of the neurons in the input will be randomly set to 0 to prevent overfitting.\n",
    "selfembdrop = nn.Dropout(0.4)\n",
    "new_cat_col = selfembdrop(new_cat_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124af55e-0918-4211-a1db-65b6b6d5ae6e",
   "metadata": {},
   "source": [
    "## By using similar approach let's design the ANN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "79cf5aae-a064-4530-a965-4a9defd569c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Here layers is a list consisting of no of neurons at different layers. y_out = number of nodes at output layer.\n",
    "    def __init__(self,n_cont,emb_sizes,layers,y_out,p): \n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_sizes])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont) # Normalizing the continuous features.\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_sizes))\n",
    "        n_in = n_emb + n_cont # n_in = total Number of inputs\n",
    "        \n",
    "        # Creating ANN structure\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],y_out))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "\n",
    "    def forward(self,x_cat,x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(selfembeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        \n",
    "        # Applying the layer object to data\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        \n",
    "        # Combining the continuous and categorical data\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f0cd0f74-7aaa-4ca4-b09b-ce78fe73248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = Model(cont_col.shape[1], emb_sizes, [200,100], 2, p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1c7442a2-5a47-461b-8e78-8e76491c93d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "b0bb40bc-a969-46d1-9564-43a903030766",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812a5cb-ae54-4365-bf3f-1070cb1794b8",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "Total records are large in number. So, we are diving it into batches of 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "59cca759-2798-4b93-8075-3a8005f77aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cat_col[:batch_size-test_size]\n",
    "cat_test = cat_col[batch_size-test_size:batch_size]\n",
    "cont_train = cont_col[:batch_size-test_size]\n",
    "cont_test = cont_col[batch_size-test_size:batch_size]\n",
    "y_train = y_col[:batch_size-test_size]\n",
    "y_test = y_col[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "3dd8416a-38e0-4a77-8a35-c69ffaa44a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "13d3e959-a793-4843-aceb-1a6d8d362cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 & loss = 0.906693696975708\n",
      "epoch : 11 & loss = 0.6820188164710999\n",
      "epoch : 21 & loss = 0.6268951296806335\n",
      "epoch : 31 & loss = 0.5978077054023743\n",
      "epoch : 41 & loss = 0.5852499604225159\n",
      "epoch : 51 & loss = 0.5701016783714294\n",
      "epoch : 61 & loss = 0.5628886222839355\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[391], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcont_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# y_pred\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(criterion(y_pred , y_train))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[385], line 34\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x_cat, x_cont)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Combining the continuous and categorical data\u001b[39;00m\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, x_cont], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 350\n",
    "losses = []\n",
    "for i in range(1,epoch+1):\n",
    "    y_pred = model(cat_train, cont_train)\n",
    "    # y_pred\n",
    "    loss = torch.sqrt(criterion(y_pred , y_train))\n",
    "    losses.append(loss)\n",
    "    if i%10 == 1:\n",
    "        print(f'epoch : {i} & loss = {loss.item()}')\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c000c8-2daf-448d-b8bd-848ee70da747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(epoch), [losses[i].detach().numpy() for i in range(len(losses))])\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.xlabel('epoch');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b70a07-f565-443c-82cc-20ca7e67ff24",
   "metadata": {},
   "source": [
    "## Let's Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ef1cd-7ea9-48df-8177-154afc0a623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "\n",
    "# To not change the weights and biases of our model we use torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, cont_test)\n",
    "    loss = torch.sqrt(criterion(y_val, y_test))\n",
    "print(f'RMSE: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0667f8-78d9-40f2-a501-a9e996c14b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e43937-eb11-4317-9027-947dfbe8916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy\n",
    "correct = 0\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i].argmax().item() == y_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f'Accuracy of the model is: {correct/len(y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8670a-608b-4cf0-83d3-38c38df8ba0f",
   "metadata": {},
   "source": [
    "Now, here we can see that accuracy of the model to predict the fare_class is around 91%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ade7de-301c-46e1-aa47-844bde4b7164",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9457061f-69a1-4c82-b034-1c0b023983eb",
   "metadata": {},
   "source": [
    "We can save a trained model to a file in case we want to come back later and feed new data through it. The best practice is to save the state of the model (weights & biases) and not the full definition. Also, we want to ensure that only a trained model is saved, to prevent overwriting a previously saved model with an untrained one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa4247-5ce3-4eec-8775-76f1a385c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to save the model only after the training has happened!\n",
    "if len(losses) == epoch:\n",
    "    torch.save(model.state_dict(), 'TaxiFareEstimation.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f115f-4d26-4f8c-bf39-6f1174686fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f3c62-60af-40c0-a3e4-f475f3bef9db",
   "metadata": {},
   "source": [
    "## Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd07456-3e48-4563-a1df-4dab1b8729c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('TaxiFareEstimation.pt', weights_only=True))\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d879a9-e9bb-4e5f-a9e1-d252fb0abf53",
   "metadata": {},
   "source": [
    "## Predicting from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bfc25-8da5-4dcc-a545-09a74f276f46",
   "metadata": {},
   "source": [
    "Let's take 5 records from the dataset and assume it to be an unseen data, just to be sure that our model is working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb9eca9-760b-4d62-b9e8-5f002cf90960",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0,len(cat_test),5)\n",
    "cat_unseen = cat_test[idx]\n",
    "cont_unseen = cont_test[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_unseen = model(cat_unseen, cont_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bf2dd-edd5-4fc6-b779-07988fe8b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_unseen)):\n",
    "    print(y_unseen[i].argmax().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
